Vision lab3 rough work
________________________________________________

ok so I've tried surf with the decent transformed image and the bookviews, I get the feeling that if I can isolate the page from the background then there is a good chance I can classify the image

so we have blue dots, now lets try doing a hough for a circle

using blur and otsu thresholding to get a binary image of the blue dots, adaptive thresholding included a lot of outside parts

now we need to connect the dots

I could find all the clusters of white in the image and mark them as dots. Then I could get the slopes between each of them and if pairings matched then that is a line. Start at the top and get the top points

lets try hough one more time

working pretty well, a few really large cluster mess it up though, going to try an remove them, esp image 35, 36 +

cluster deletion works
#todo get points of intersection, bottom points are bottomright, rightmost are topright et

erode all points down to 1 pixel

min bottom length: 350
min top length: 460

get distance between points

min-distance-between = 85

min width into the photo = 300

rows/cols is as you would expect, cols > rows	

right so doing blur and thresholding on the hough lines is interesting, going to see if we can use non-maxima surpression to get the line thinner
another option might be starting again using edge detection and see how good we can get it

OOOOH maybe use a corner detector on our output - nope

could look for any 3 image points which are a certain proportion or width from each other

ok will do all that later, for the time being have perspective transformation working perfectly basically for the first few images

now onto sift, using the flann.cpp file can't really distinguish, however the output is blurred and the input is crisp, so going to try and sharpen the output and blur the input - sharpening worked perfectly!

turning out to be kinda tricky the sharpen the image or get it to match perfectly with thresholding, definately possible though - oh maybe not

sharpening may not be the way to go

sift simple doesn't pick up images, chamfering might be good

could just consider bottom half of transformed image as it is least blurry

so chamfer isn't working for some strange reason, from intial inspection it should at least generate the champfer values although I don't know how to display them

now going for idea of using in built template matching function and to match a ROI area of the image, and see if any match

standard template looks like the way to go if we can output a probability
